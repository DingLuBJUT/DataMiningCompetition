{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from  sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from bubbly.bubbly import bubbleplot\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import pylab as pl\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/dinglu/Documents/code/DataMining/Risk_Prediction_Of_Illegal_Fund_Raising/data/\"\n",
    "path_base_info = root + \"train/base_info.csv\"\n",
    "path_annual_report_info = root + \"train/annual_report_info.csv\"\n",
    "path_change_info = root + \"train/change_info.csv\"\n",
    "path_news_info = root + \"train/news_info.csv\"\n",
    "path_other_info = root + \"train/other_info.csv\"\n",
    "path_tax_info = root + \"train/tax_info.csv\"\n",
    "path_entprise_evaluate = root + \"entprise_evaluate.csv\"\n",
    "path_entprise_info = root + \"train/entprise_info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseInfo:\n",
    "    def __init__(self, data, type='train'):\n",
    "        self.data = data\n",
    "        self.data_type = {\n",
    "            'opfrom': 'time',\n",
    "            'opto': 'time',\n",
    "            'reccap': 'int64',\n",
    "            'enttypeminu': 'category',\n",
    "            'venind': 'category',\n",
    "            'enttypeitem': 'category',\n",
    "            'empnum': 'int64',\n",
    "            'regcap': 'int64',\n",
    "            'industryco': 'category',\n",
    "            'oploc': 'category',\n",
    "            'oplocdistrict': 'category',\n",
    "            'regtype': 'category',\n",
    "            'townsign': 'category',\n",
    "            'adbusign': 'category',\n",
    "            'jobid': 'category',\n",
    "            'orgid': 'category',\n",
    "            'state': 'category',\n",
    "            'enttype': 'category',\n",
    "            'dom': 'category',\n",
    "            'industryphy': 'category',\n",
    "            'enttypegb': 'category',\n",
    "            'opform': 'category'\n",
    "        }\n",
    "        self.useless_columns = [\n",
    "            'ptbusscope',\n",
    "            'midpreindcode',\n",
    "            'protype',\n",
    "            'forreccap',\n",
    "            'congro',\n",
    "            'forregcap',\n",
    "            'exenum',\n",
    "            'parnum',\n",
    "            'compform',\n",
    "            'opscope',\n",
    "            'id'\n",
    "\n",
    "#             'orgid',\n",
    "#             'industryco',\n",
    "#             'dom',\n",
    "#             'enttypegb',\n",
    "#             'enttypeitem',\n",
    "#             'opfrom',\n",
    "#             'state',\n",
    "#             'adbusign',\n",
    "#             'jobid',\n",
    "#             'enttypegb',\n",
    "#             'regtype',\n",
    "#             'empnum',\n",
    "#             'venind',\n",
    "#             'enttypeminu',\n",
    "#             'oploc',\n",
    "#             'enttype',\n",
    "#             'oplocdistrict'\n",
    "\n",
    "        ]\n",
    "\n",
    "        if type == 'test':\n",
    "            self.useless_columns.remove('id')\n",
    "            self.useless_columns.append('score')\n",
    "\n",
    "        return\n",
    "\n",
    "    def fill_nan(self, name, value, column_type):\n",
    "        self.data[name] = self.data[name].fillna(value)\n",
    "        self.data[name] = self.data[name].astype(column_type)\n",
    "        return\n",
    "\n",
    "    def label_encoder(self, name, column_type):\n",
    "        label_encode = LabelEncoder()\n",
    "        value_data = self.data[self.data[name].isnull() == 0]\n",
    "        null_data = self.data[self.data[name].isnull() != 0]\n",
    "        value_data[name] = label_encode.fit_transform(value_data[name])\n",
    "        self.data = pd.concat([null_data, value_data])\n",
    "        self.data[name] = self.data[name].astype(column_type)\n",
    "        return\n",
    "\n",
    "    def drop_columns(self, drop_columns):\n",
    "        self.data.drop(drop_columns, axis=1, inplace=True)\n",
    "        return\n",
    "\n",
    "    def unify_time(self, name):\n",
    "        value_data = self.data[self.data[name].isnull() == 0]\n",
    "        null_data = self.data[self.data[name].isnull() != 0]\n",
    "        value_data[name] = value_data[name].apply(\n",
    "            lambda x: x if len(x) > 10 else (x + \" 00:00:00\"))\n",
    "        value_data[name] = value_data[name].apply(\n",
    "            lambda x: x if x is None else datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "        value_data[name] = value_data[name].apply(lambda x: x.year)\n",
    "        self.data = pd.concat([value_data, null_data])\n",
    "        return\n",
    "\n",
    "    def feature_process_v1(self):\n",
    "        for name in self.data_type.keys():\n",
    "            if self.data_type.get(name) == 'category':\n",
    "                self.label_encoder(name,'category')\n",
    "            elif self.data_type.get(name) == 'int64':\n",
    "                mean = self.data[self.data[name].isnull() == 0][name].mean()\n",
    "                self.fill_nan(name, mean, 'int64')\n",
    "            elif self.data_type.get(name) == 'time':\n",
    "                self.unify_time(name)\n",
    "                mode = self.data[name].mode()[0]\n",
    "                self.fill_nan(name, mode, 'int64')\n",
    "\n",
    "        self.data['diff_year'] = (self.data['opto'] - self.data['opfrom']).astype('int64')\n",
    "        self.drop_columns(self.useless_columns)\n",
    "        return self.data\n",
    "    \n",
    "    def feature_process_v2(self):\n",
    "        for name in self.data_type.keys():\n",
    "            if self.data_type.get(name) == 'category':\n",
    "                self.fill_nan(name, '-1', 'str')\n",
    "                self.label_encoder(name, 'category')\n",
    "            elif self.data_type.get(name) == 'int64':\n",
    "                mean = self.data[self.data[name].isnull() == 0][name].mean()\n",
    "                self.fill_nan(name, mean, 'int64')\n",
    "            elif self.data_type.get(name) == 'time':\n",
    "                self.unify_time(name)\n",
    "                mode = self.data[name].mode()[0]\n",
    "                self.fill_nan(name, mode, 'int64')\n",
    "\n",
    "        self.data['diff_year'] = (self.data['opto'] - self.data['opfrom']).astype('int64')\n",
    "        self.drop_columns(self.useless_columns)\n",
    "        return self.data\n",
    "    \n",
    "def split_data(data_frame, split_ratio):\n",
    "    label = data_frame[['label']]\n",
    "    data_frame.drop(['label'], axis=1, inplace=True)\n",
    "    train_data, val_data, train_label, val_label = train_test_split(data_frame,\n",
    "                                                                    label,\n",
    "                                                                    test_size=split_ratio,\n",
    "                                                                    random_state=2020)\n",
    "    return train_data, val_data, train_label, val_label\n",
    "\n",
    "\n",
    "\n",
    "def get_balance_data(data_frame):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data_frame:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pos_data = data_frame[data_frame['label'] == 1]\n",
    "    neg_data = data_frame[data_frame['label'] == 0]\n",
    "    neg_data = neg_data.sample(n=len(pos_data), axis=0, random_state=2020, replace=True)\n",
    "    data_frame = pd.concat([neg_data, pos_data])\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def predict_data(data_frame, model):\n",
    "    label = data_frame['label']\n",
    "    data_frame.drop(['label'], inplace=True, axis=1)\n",
    "    prob = pd.Series(model.predict_proba(data_frame)[:, 1], name='prob')\n",
    "    data_frame = pd.concat([data_frame.reset_index(), label.reset_index(), prob.reset_index()], axis=1)\n",
    "    pred = pd.Series([1 if prob > 0.5 else 0 for prob in data_frame['prob']], name='pred')\n",
    "    data_frame = pd.concat([data_frame, pred.reset_index()], axis=1)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(data_frame):\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    label = data_frame['label']\n",
    "    pred = data_frame['pred']\n",
    "    conf_matrix = confusion_matrix(label, pred)\n",
    "    print(conf_matrix)\n",
    "\n",
    "    neg_to_neg = conf_matrix[0, 0]\n",
    "    pos_to_neg = conf_matrix[0, 1]\n",
    "    neg_to_pos = conf_matrix[1, 0]\n",
    "    pos_to_pos = conf_matrix[1, 1]\n",
    "\n",
    "    pos_acc = pos_to_pos / (pos_to_pos + pos_to_neg)\n",
    "    neg_acc = neg_to_neg / (neg_to_neg + neg_to_pos)\n",
    "\n",
    "    print(\"neg acc is: %f\" % (neg_acc))\n",
    "    print(\"pos acc is: %f\" % (pos_acc))\n",
    "\n",
    "    sns.heatmap(conf_matrix, annot=True, ax=ax)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels');\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['0', '1'])\n",
    "    ax.yaxis.set_ticklabels(['0', '1'])\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def predict_result(model, test_data, result_path):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param test_data:\n",
    "    :param result_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    test_id = test_data['id']\n",
    "    test_data.drop(['id'], inplace=True, axis=1)\n",
    "    test_prob = model.predict_proba(test_data)[:, 1]\n",
    "    result = pd.DataFrame({'id': test_id, 'score': test_prob})\n",
    "#     result = result.groupby(\"id\").agg('mean').reset_index()\n",
    "    result.to_csv(result_path, index=False)\n",
    "    return\n",
    "\n",
    "def plot_SHAP(tree_model, val_data):\n",
    "    values = shap.TreeExplainer(tree_model).shap_values(val_data)\n",
    "    shap.summary_plot(values, tree_model)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entprise_info = pd.read_csv(path_entprise_info)\n",
    "df_base_info = pd.read_csv(path_base_info)\n",
    "df_annual_report_info = pd.read_csv(path_annual_report_info)\n",
    "df_entprise_evaluate = pd.read_csv(path_entprise_evaluate)\n",
    "df_tax_info = pd.read_csv(path_tax_info)\n",
    "df_other_info = pd.read_csv(path_other_info)\n",
    "df_news_info = pd.read_csv(path_news_info)\n",
    "df_change_info = pd.read_csv(path_change_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info = BaseInfo(train_data)\n",
    "train_data = base_info.feature_process_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_balance_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = split_data(train_data, split_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param_list = {\n",
    "    'boosting_type':'gbdt',\n",
    "    'objective_type':'binary',\n",
    "    'n_estimators':200,\n",
    "    'learning_rate':0.08,\n",
    "    'max_depth':5,\n",
    "    'num_leaves':31,\n",
    "    'subsample':0.7, \n",
    "    'colsample_bytree':0.5,\n",
    "    'subsample_freq':1, \n",
    "    'min_split_gain':0.5,\n",
    "    'min_child_samples':50, \n",
    "    'reg_alpha':3.5, \n",
    "    'reg_lambda':3.0,\n",
    "    'random_state':2019, \n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_param_list)\n",
    "lgb_clf = lgb_model.fit(train_x,\n",
    "                        train_y,\n",
    "                        eval_set=[(train_x,train_y),(val_x,val_y)],\n",
    "#                         categorical_feature = categorical_columns,\n",
    "                        eval_metric=\"binary_error\",\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_data = predict_data(train_data, lgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(predict_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info = BaseInfo(test_data,'test')\n",
    "test_data = base_info.feature_process_v2()\n",
    "predict_result(lgb_clf, test_data, root + 'result/baseline_8.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
