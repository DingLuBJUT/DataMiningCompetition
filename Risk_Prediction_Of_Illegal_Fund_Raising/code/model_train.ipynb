{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from  sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from bubbly.bubbly import bubbleplot\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/dinglu/Documents/code/DataMining/Risk_Prediction_Of_Illegal_Fund_Raising/data/\"\n",
    "path_base_info = root + \"train/base_info.csv\"\n",
    "path_annual_report_info = root + \"train/annual_report_info.csv\"\n",
    "path_change_info = root + \"train/change_info.csv\"\n",
    "path_news_info = root + \"train/news_info.csv\"\n",
    "path_other_info = root + \"train/other_info.csv\"\n",
    "path_tax_info = root + \"train/tax_info.csv\"\n",
    "path_entprise_evaluate = root + \"entprise_evaluate.csv\"\n",
    "path_entprise_info = root + \"train/entprise_info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseInfo:\n",
    "    def __init__(self, data, type='train'):\n",
    "        self.data = data\n",
    "        self.data_type = {\n",
    "            'opfrom': 'time',\n",
    "            'opto': 'time',\n",
    "            'reccap': 'int64',\n",
    "            'enttypeminu': 'category',\n",
    "            'venind': 'category',\n",
    "            'enttypeitem': 'category',\n",
    "            'empnum': 'int64',\n",
    "            'regcap': 'int64',\n",
    "            'industryco': 'category',\n",
    "            'oploc': 'category',\n",
    "            'oplocdistrict': 'category',\n",
    "            'regtype': 'category',\n",
    "            'townsign': 'category',\n",
    "            'adbusign': 'category',\n",
    "            'jobid': 'category',\n",
    "            'orgid': 'category',\n",
    "            'state': 'category',\n",
    "            'enttype': 'category',\n",
    "            'dom': 'category',\n",
    "            'industryphy': 'category',\n",
    "            'enttypegb': 'category',\n",
    "            'opform': 'category'\n",
    "        }\n",
    "        self.useless_columns = [\n",
    "            'ptbusscope',\n",
    "            'midpreindcode',\n",
    "            'protype',\n",
    "            'forreccap',\n",
    "            'congro',\n",
    "            'forregcap',\n",
    "            'exenum',\n",
    "            'parnum',\n",
    "            'compform',\n",
    "            'opscope',\n",
    "            'id',\n",
    "        ]\n",
    "\n",
    "        if type == 'test':\n",
    "            self.useless_columns.remove('id')\n",
    "            self.useless_columns.append('score')\n",
    "\n",
    "        return\n",
    "\n",
    "    def fill_nan(self, name, value, column_type):\n",
    "        self.data[name] = self.data[name].fillna(value)\n",
    "        self.data[name] = self.data[name].astype(column_type)\n",
    "        return\n",
    "\n",
    "    def label_encoder(self, name, column_type):\n",
    "        label_encode = LabelEncoder()\n",
    "        value_data = self.data[self.data[name].isnull() == 0]\n",
    "        null_data = self.data[self.data[name].isnull() != 0]\n",
    "        value_data[name] = label_encode.fit_transform(value_data[name])\n",
    "        self.data = pd.concat([null_data, value_data])\n",
    "        self.data[name] = self.data[name].astype(column_type)\n",
    "        return\n",
    "\n",
    "    def drop_columns(self, drop_columns):\n",
    "        self.data.drop(drop_columns, axis=1, inplace=True)\n",
    "        return\n",
    "\n",
    "    def unify_time(self, name):\n",
    "        value_data = self.data[self.data[name].isnull() == 0]\n",
    "        null_data = self.data[self.data[name].isnull() != 0]\n",
    "        value_data[name] = value_data[name].apply(\n",
    "            lambda x: x if len(x) > 10 else (x + \" 00:00:00\"))\n",
    "        value_data[name] = value_data[name].apply(\n",
    "            lambda x: x if x is None else datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "        value_data[name] = value_data[name].apply(lambda x: x.year)\n",
    "        self.data = pd.concat([value_data, null_data])\n",
    "        return\n",
    "\n",
    "\n",
    "    def process_v1(self):\n",
    "        for name in self.data_type.keys():\n",
    "            if self.data_type.get(name) == 'category':\n",
    "                self.label_encoder(name,'category')\n",
    "            elif self.data_type.get(name) == 'int64':\n",
    "                mean = self.data[self.data[name].isnull() == 0][name].mean()\n",
    "                self.fill_nan(name, mean, 'int64')\n",
    "            elif self.data_type.get(name) == 'time':\n",
    "                self.unify_time(name)\n",
    "                mode = self.data[name].mode()[0]\n",
    "                self.fill_nan(name, mode, 'int64')\n",
    "\n",
    "        self.data['diff_year'] = (self.data['opto'] - self.data['opfrom']).astype('int64')\n",
    "        self.drop_columns(self.useless_columns)\n",
    "        return self.data\n",
    "\n",
    "def get_balance_data(data_frame):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data_frame:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pos_data = data_frame[data_frame['label'] == 1]\n",
    "    neg_data = data_frame[data_frame['label'] == 0]\n",
    "    neg_data = neg_data.sample(n=len(pos_data), axis=0, random_state=2020, replace=True)\n",
    "    data_frame = pd.concat([neg_data, pos_data])\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def probed_data(data_frame, model):\n",
    "    label = data_frame['label']\n",
    "    data_frame.drop(['label'], inplace=True, axis=1)\n",
    "    prob = pd.Series(model.predict_proba(data_frame)[:, 1], name='prob')\n",
    "    data_frame = pd.concat([data_frame.reset_index(),label.reset_index(),prob.reset_index()],axis=1)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def predict_result(model, test_data, result_path):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param test_data:\n",
    "    :param result_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    test_id = test_data['id']\n",
    "    test_data.drop(['id'], inplace=True, axis=1)\n",
    "    test_prob = model.predict_proba(test_data)[:, 1]\n",
    "    result = pd.DataFrame({'id': test_id, 'score': test_prob})\n",
    "#     result = result.groupby(\"id\").agg('mean').reset_index()\n",
    "    result.to_csv(result_path, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entprise_info = pd.read_csv(path_entprise_info)\n",
    "df_base_info = pd.read_csv(path_base_info)\n",
    "df_annual_report_info = pd.read_csv(path_annual_report_info)\n",
    "df_entprise_evaluate = pd.read_csv(path_entprise_evaluate)\n",
    "df_tax_info = pd.read_csv(path_tax_info)\n",
    "df_other_info = pd.read_csv(path_other_info)\n",
    "df_news_info = pd.read_csv(path_news_info)\n",
    "df_change_info = pd.read_csv(path_change_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(df_entprise_info, df_base_info, how='inner', on='id')\n",
    "test_data = pd.merge(df_entprise_evaluate, df_base_info, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_info = BaseInfo(train_data)\n",
    "train_data = base_info.process_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_balance_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = split_data(train_data, split_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_error: 0.0305949\ttraining's binary_logloss: 0.625462\tvalid_1's binary_error: 0.035533\tvalid_1's binary_logloss: 0.627177\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_error: 0.0300283\ttraining's binary_logloss: 0.644165\tvalid_1's binary_error: 0.035533\tvalid_1's binary_logloss: 0.645504\n"
     ]
    }
   ],
   "source": [
    "lgb_param_list = {\n",
    "    'boosting_type':'gbdt',\n",
    "    'objective_type':'binary',\n",
    "    'n_estimators':200,\n",
    "    'learning_rate':0.01,\n",
    "    'max_depth':5,\n",
    "    'num_leaves':31,\n",
    "    'subsample':0.7, \n",
    "    'colsample_bytree':0.5,\n",
    "    'subsample_freq':1, \n",
    "    'min_split_gain':0.5,\n",
    "    'min_child_samples':50, \n",
    "    'reg_alpha':3.5, \n",
    "    'reg_lambda':3.0,\n",
    "    'random_state':2019, \n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_param_list)\n",
    "lgb_clf = lgb_model.fit(train_x,\n",
    "                        train_y,\n",
    "                        eval_set=[(train_x,train_y),(val_x,val_y)],\n",
    "#                         categorical_feature = categorical_columns,\n",
    "                        eval_metric=\"binary_error\",\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train_data = probed_data(train_data, lgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_info = BaseInfo(test_data,'test')\n",
    "test_data = base_info.process_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result(lgb_clf, test_data, root + \"result/baseline_7.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
